import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from requests.exceptions import RequestException

HEADERS = {
    "User-Agent": "Mozilla/5.0 (AdvancedSecurityScanner)"
}

TIMEOUT = 5

PAYLOADS = {
    "SQL Injection": "' OR '1'='1",
    "XSS": "<script>alert(1)</script>"
}

SQL_ERRORS = [
    "you have an error in your sql syntax",
    "warning: mysql",
    "unclosed quotation mark",
    "quoted string not properly terminated",
    "mysql_fetch",
    "sql error"
]

ADMIN_ENDPOINTS = [
    "admin/", "administrator/", "admin.php", "dashboard/"
]

AUTH_ENDPOINTS = [
    "login.php", "register.php", "signup.php",
    "profile.php", "account.php", "reset.php"
]

INPUT_ENDPOINTS = [
    "search.php", "view.php", "item.php",
    "product.php", "comment.php", "feedback.php"
]

DEBUG_ENDPOINTS = [
    "test/", "dev/", "old/", "backup/", "staging/"
]

COMMON_PARAMETERS = [
    "id",
    "item",
    "product",
    "cat",
    "category",
    "search",
    "query",
    "q",
    "name",
    "username",
    "email",
    "comment",
    "message",
    "firstname",
    "lastname"
]

COMMON_ENDPOINTS = list(
    set(ADMIN_ENDPOINTS + AUTH_ENDPOINTS + INPUT_ENDPOINTS + DEBUG_ENDPOINTS)
)

def normalize_url(url):
    if not url.startswith(("http://", "https://")):
        url = "http://" + url
    return url.rstrip("/")


def same_domain(base, target):
    return urlparse(base).netloc == urlparse(target).netloc


def is_sql_error(text):
    text = text.lower()
    return any(err in text for err in SQL_ERRORS)

def discover_common_endpoints(base_url):
    discovered = []
    for ep in COMMON_ENDPOINTS:
        discovered.append(urljoin(base_url + "/", ep))
    return discovered


def discover_robots_paths(base_url, session):
    paths = []
    try:
        r = session.get(base_url + "/robots.txt", timeout=TIMEOUT)
        if r.status_code == 200:
            for line in r.text.splitlines():
                if line.lower().startswith("disallow:"):
                    path = line.split(":", 1)[1].strip()
                    if path and path != "/":
                        paths.append(urljoin(base_url + "/", path))
    except RequestException:
        pass
    return paths

def get_forms(url, session):
    try:
        r = session.get(url, timeout=TIMEOUT)
        soup = BeautifulSoup(r.text, "html.parser")
        return soup.find_all("form")
    except RequestException:
        return []


def submit_form(form, page_url, payload, session):
    action = form.get("action")
    method = form.get("method", "get").lower()
    target_url = urljoin(page_url, action)

    data = {}
    for tag in form.find_all("input"):
        name = tag.get("name")
        if name:
            data[name] = payload

    try:
        if method == "post":
            return session.post(target_url, data=data, timeout=TIMEOUT)
        else:
            return session.get(target_url, params=data, timeout=TIMEOUT)
    except RequestException:
        return None

def scan_url_parameters(url, session):
    results = []

    for param in COMMON_PARAMETERS:
        for attack, payload in PAYLOADS.items():
            try:
                r = session.get(
                    url,
                    params={param: payload},
                    timeout=TIMEOUT
                )

                text = r.text.lower()

                if payload.lower() in text:
                    results.append(
                        (attack, f"VULNERABLE (Reflected via '{param}')")
                    )
                elif attack == "SQL Injection" and is_sql_error(text):
                    results.append(
                        (attack, f"VULNERABLE (SQL Error via '{param}')")
                    )

            except RequestException:
                continue

    if not results:
        results.append(("Info", "No reflected or error-based issues detected"))

    return results

def scan_forms(url, session):
    results = []
    forms = get_forms(url, session)

    for form in forms:
        for attack, payload in PAYLOADS.items():
            r = submit_form(form, url, payload, session)
            if r:
                text = r.text.lower()
                if payload.lower() in text:
                    results.append((attack, "VULNERABLE (Form Input)"))
                elif attack == "SQL Injection" and is_sql_error(text):
                    results.append((attack, "VULNERABLE (SQL Error Based)"))
                else:
                    results.append((attack, "Not Detected"))
            else:
                results.append((attack, "Blocked / Failed"))
    return results

def main():
    target = normalize_url(input("Enter target URL: ").strip())

    session = requests.Session()
    session.headers.update(HEADERS)

    print("\n[+] Starting Advanced Vulnerability Scan")
    print("[+] Base Target:", target)
    print("-" * 60)

    endpoints = set()
    endpoints.add(target)

    endpoints.update(discover_common_endpoints(target))
    endpoints.update(discover_robots_paths(target, session))

    print(f"[+] Discovered {len(endpoints)} endpoints (controlled)")
    print("-" * 60)

    for url in endpoints:
        if not same_domain(target, url):
            continue

        print(f"\n[>] Scanning: {url}")

        url_results = scan_url_parameters(url, session)
        form_results = scan_forms(url, session)

        for attack, result in url_results:
            print(f"  [URL] {attack}: {result}")

        for attack, result in form_results:
            print(f"  [FORM] {attack}: {result}")

    print("\n[+] Scan Completed")


if __name__ == "__main__":
    main()
